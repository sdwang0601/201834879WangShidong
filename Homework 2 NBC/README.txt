项目介绍：
代码文件：NBC.py
其他文件夹：

NBC.py
代码实现的主要功能介绍如下：

  朴素贝叶斯算法的核心思想，是选择训练集中具有最高后验概率的类别作为测试数据的预测类别。
  下面介绍利用Python语言实现朴素贝叶斯算法的过程，其本质是利用词和类别的联合概率来预测给定文档属于某个类别。

1.数据集的准备
  本实验所用数据集已经预处理完成，共包含20个类别，
  每个类别中包含若干文本文档，每个文本文档里包含若干单词，每个单词占一行。

1）生成训练集向量
  此过程返回一个训练集向量集合，list的格式为：[[str,int,float,dict],  [],[]]。
  其中，str为某个类别，
  int为该类别所有文档的单词总数（一个单词在一个文档中只计算一次），
  float为P(Ci)的值（该类别的文档总数/数据集文档总数）,
  dict为该类别的字典，字典的value值为该类别所有单词的df值（包含该单词的文档总数）。

2）生成测试集向量
  此过程返回一个测试集向量集合，list的格式为：[[str,list],  [],[]]。
  其中，str为测试集该向量所属的类别，
  list为测试集该向量所包含的所有单词集合（无重复单词）。
        
2.NBC算法实现
1）装载数据：导入第一步已经预处理完成的训练集和测试集的向量集合
2）模型应用（伯努利朴素贝叶斯模型）：本实验采用的伯努利朴素贝叶斯模型，统计（训练）时和判断（测试）时均不考虑重复单词；
3）Laplace平滑：若测试数据中有的单词在训练集没有出现，其概率就是0，会十分影响分类器的性能，
   所以采取Laplace平滑，让分子各单词的出现次数默认加1，让分母单词出现总数加上测试数据的单词总数，这样处理后不影响相对大小。
4）解决下溢问题：若很小是数字相乘，则结果会更小，再四舍五入存在误差，而且会造成下溢出。
   所以对概率值取log，乘法变为加法，并且相对大小趋势不变。
5) 模型性能评测：记录模型预测成功与失败次数，计算并输出模型预测准确率。
   
3.模型预测结果
  训练集装载完成！ 数据集大小：  20
  测试集装载完成！ 数据集大小：  15074
  该模型的性能：
  总测试次数： 15074
  预测成功次数： 14168
  预测失败次数： 906
  预测准确率： 0.9398965105479634
 
